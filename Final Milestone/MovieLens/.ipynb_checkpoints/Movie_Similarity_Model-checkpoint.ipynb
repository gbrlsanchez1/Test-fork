{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def elapsed_time(title):\n",
    "    start = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - start\n",
    "    print '%s: %.2f secs' % (title, elapsed)\n",
    "\n",
    "\n",
    "def get_xy(ratings_df):\n",
    "    y = ratings_df['rating']\n",
    "    x = ratings_df.drop('rating', axis=1)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def date_parse(time_in_secs):\n",
    "    return datetime.utcfromtimestamp(float(time_in_secs))\n",
    "\n",
    "\n",
    "def read_ratings_df_with_timestamp(file_name):\n",
    "    with elapsed_time('loaded csv'):\n",
    "        ratings_df = pd.read_csv(file_name, parse_dates=['timestamp'], date_parser=date_parse)\n",
    "    return ratings_df\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaselineModel(object):\n",
    "    def predict_rating(self, user_id, movie_id):\n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "        return [self.predict_rating(row['userId'], row['movieId']) for _, row in x.iterrows()]\n",
    "\n",
    "    def score(self, x, y):\n",
    "        return r2_score(y, self.predict(x))\n",
    "\n",
    "    \n",
    "class BaselineEffectsModel(BaselineModel):\n",
    "    def __init__(self, movie_lambda=5.0, user_lambda=20.0):\n",
    "        self.movie_lambda = movie_lambda\n",
    "        self.user_lambda = user_lambda\n",
    "\n",
    "        self.y_mean = None\n",
    "        self.movie_effects = None\n",
    "        self.user_effects = None\n",
    "        self.user_groups = None\n",
    "\n",
    "    def calculate_movie_effect(self, ratings):\n",
    "        return (ratings - self.y_mean).sum() / (self.movie_lambda + len(ratings))\n",
    "\n",
    "    def calculate_movie_effects(self, movie_ratings):\n",
    "        return movie_ratings.agg(lambda ratings: self.calculate_movie_effect(ratings))\n",
    "\n",
    "    def calculate_user_effect(self, ratings_df):\n",
    "        s = 0.0\n",
    "        for _, row in ratings_df.iterrows():\n",
    "            s += row['rating'] - self.y_mean - self.movie_effects[row['movieId']]\n",
    "\n",
    "        return s / (self.user_lambda + len(ratings_df))\n",
    "\n",
    "    def calculate_user_effects(self, user_groups):\n",
    "        user_ids = []\n",
    "        user_effects = []\n",
    "\n",
    "        for user_id, group in user_groups:\n",
    "            user_effect = self.calculate_user_effect(group)\n",
    "\n",
    "            user_ids.append(user_id)\n",
    "            user_effects.append(user_effect)\n",
    "\n",
    "        return pd.Series(user_effects, index=user_ids)\n",
    "\n",
    "    def fit(self, ratings_df):\n",
    "        with elapsed_time('effects init'):\n",
    "            _, y_train = get_xy(ratings_df)\n",
    "            self.y_mean = y_train.mean()\n",
    "\n",
    "            movie_ratings = ratings_df.groupby('movieId')['rating']\n",
    "            self.user_groups = ratings_df.groupby('userId')\n",
    "\n",
    "            self.movie_effects = self.calculate_movie_effects(movie_ratings)\n",
    "            self.user_effects = self.calculate_user_effects(self.user_groups)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def create_modified_ratings(self, ratings_df):\n",
    "        ratings_df = ratings_df.copy()\n",
    "\n",
    "        for index, row in ratings_df.iterrows():\n",
    "            user_id = row['userId']\n",
    "            movie_id = row['movieId']\n",
    "            rating = row['rating']\n",
    "            pred_rating = self.predict_baseline_rating(user_id, movie_id)\n",
    "\n",
    "            residual = rating - pred_rating\n",
    "\n",
    "            ratings_df.loc[index, 'rating'] = residual\n",
    "\n",
    "        return ratings_df\n",
    "\n",
    "    def predict_baseline_rating(self, user_id, movie_id):\n",
    "        return self.y_mean + self.movie_effects.get(movie_id, 0.0) + self.user_effects[user_id]\n",
    "\n",
    "    def predict_rating(self, user_id, movie_id):\n",
    "        return self.predict_baseline_rating(user_id, movie_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie similarity model.\n",
    "\n",
    "First we removed all main global effects the same way as we did for our baseline model.\n",
    "We subtracted the total rating mean, then we removed the movie effects and then user effects.\n",
    "\n",
    "As a result our utility matrix was the residuals after applying our baseline models. \n",
    "\n",
    "It allowed us to remove some scale differences in the way different users rate movies.\n",
    "\n",
    "In our movie similarity model we predict the rating for a movie (movie_id) and a user (user_id) by\n",
    "\n",
    "1) finding k closest neighbors (k=40)\n",
    "\n",
    "For assessing item-item similarity we used a distance based on the mean squared error between items [1]:\n",
    "\n",
    "$s_{ij}=\\frac{|U(i,j)|}{\\sum_{u \\in U(i,j)} (r_{ui}-r_{uj})^2 + \\alpha}$, where U(i,j) is the set of users who rated both items j and k.\n",
    "\n",
    "2) since relatively large number of movies have low number of ratings (1-3), some of the movies have zero neighbors, in this case we use a baseline prediction (in 6.9-7.2% of the cases for the test set).\n",
    "\n",
    "[1] R.Bell, Y.Koren, \"Improved Neighborhood-based Collaborative Filtering\", *KDD-Cup and Workshop*, ACM press, 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded csv: 0.49 secs\n",
      "effects init: 6.79 secs\n",
      "fit: 124.39 secs\n",
      "used baseline predictions: 3.9%\n",
      "used baseline predictions: 6.9%\n",
      "train score: 0.6667, test score: 0.3077\n",
      "train rmse: 0.6117, test rmse: 0.8769\n",
      "build model: 220.16 secs\n"
     ]
    }
   ],
   "source": [
    "MovieSimilarity = namedtuple('MovieSimilarity', ['movie_id', 'similarity'])\n",
    "\n",
    "\n",
    "class MovieSimilarityModel(BaselineModel):\n",
    "    def __init__(self):\n",
    "        self.baseline_model = BaselineEffectsModel()\n",
    "        self.ratings_by_movie = defaultdict(dict)\n",
    "        self.ratings_by_user = defaultdict(dict)\n",
    "        self.raters_by_movie = {}\n",
    "        self.movie_similarity = {}\n",
    "        # self.movie_aij = {}\n",
    "\n",
    "    def calculate_common_raters(self, movie_id_1, movie_id_2):\n",
    "        raters1 = self.raters_by_movie[movie_id_1]\n",
    "        raters2 = self.raters_by_movie[movie_id_2]\n",
    "        return raters1 & raters2\n",
    "\n",
    "    def get_common_ratings(self, movie_id, raters):\n",
    "        all_ratings = self.ratings_by_movie[movie_id]\n",
    "        ratings = []\n",
    "        for rater_id in raters:\n",
    "            ratings.append(all_ratings[rater_id])\n",
    "\n",
    "        return np.array(ratings)\n",
    "\n",
    "    def calculate_similarity(self, movie_id_1, movie_id_2):\n",
    "        common_raters = self.calculate_common_raters(movie_id_1, movie_id_2)\n",
    "        support = len(common_raters)\n",
    "        if support <= 1:\n",
    "            similarity = 0.0\n",
    "            # aij = 0.0\n",
    "        else:\n",
    "            ratings1 = self.get_common_ratings(movie_id_1, common_raters)\n",
    "            ratings2 = self.get_common_ratings(movie_id_2, common_raters)\n",
    "\n",
    "            alpha = 4.0\n",
    "\n",
    "            similarity = support / (np.power(ratings1 - ratings2, 2).sum() + alpha)\n",
    "\n",
    "            # aij = np.multiply(ratings1, ratings2).sum() / support\n",
    "\n",
    "        return similarity\n",
    "\n",
    "    def fit(self, ratings_df):\n",
    "        with elapsed_time('fit'):\n",
    "            self.baseline_model.fit(ratings_df)\n",
    "\n",
    "            ratings_df = self.baseline_model.create_modified_ratings(ratings_df)\n",
    "\n",
    "            unique_movie_ids = np.array(sorted(ratings_df['movieId'].unique()))\n",
    "\n",
    "            for _, row in ratings_df.iterrows():\n",
    "                movie_id = row['movieId']\n",
    "                user_id = row['userId']\n",
    "                rating = row['rating']\n",
    "                self.ratings_by_movie[movie_id][user_id] = rating\n",
    "                self.ratings_by_user[user_id][movie_id] = rating\n",
    "\n",
    "            for movie_id in unique_movie_ids:\n",
    "                self.raters_by_movie[movie_id] = set(self.ratings_by_movie[movie_id].keys())\n",
    "\n",
    "            for movie_index_1, movie_id_1 in enumerate(unique_movie_ids):\n",
    "                for movie_index_2 in xrange(movie_index_1 + 1, len(unique_movie_ids)):\n",
    "                    movie_id_2 = unique_movie_ids[movie_index_2]\n",
    "\n",
    "                    similarity = self.calculate_similarity(movie_id_1, movie_id_2)\n",
    "                    movie_pair = (movie_id_1, movie_id_2)\n",
    "                    self.movie_similarity[movie_pair] = similarity\n",
    "                    # self.movie_aij[movie_pair] = aij\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_similarity(self, movie_id_1, movie_id_2):\n",
    "        if movie_id_1 < movie_id_2:\n",
    "            id_1 = movie_id_1\n",
    "            id_2 = movie_id_2\n",
    "        else:\n",
    "            id_1 = movie_id_2\n",
    "            id_2 = movie_id_1\n",
    "\n",
    "        return self.movie_similarity.get((id_1, id_2), -1.0)\n",
    "\n",
    "    def clear_predict_caches(self):\n",
    "        self.zero_prediction_count = 0\n",
    "\n",
    "    def predict_rating(self, user_id, movie_id):\n",
    "        ratings = self.ratings_by_user[user_id]\n",
    "\n",
    "        elements = []\n",
    "\n",
    "        for movie_id_2 in ratings:\n",
    "            if movie_id != movie_id_2:\n",
    "                similarity = self.get_similarity(movie_id, movie_id_2)\n",
    "                if similarity > 0.0:\n",
    "                    elements.append(MovieSimilarity(movie_id_2, similarity))\n",
    "\n",
    "        k = 40\n",
    "\n",
    "        movie_similarities = heapq.nlargest(k, elements, key=lambda e: e.similarity)\n",
    "\n",
    "        if len(movie_similarities) > 0:\n",
    "            similarity_sum = 0.0\n",
    "            product_sum = 0.0\n",
    "            for movie_similarity in movie_similarities:\n",
    "                movie_id_2 = movie_similarity.movie_id\n",
    "                rating = ratings[movie_id_2]\n",
    "                similarity = movie_similarity.similarity\n",
    "\n",
    "                product_sum += similarity * rating\n",
    "                similarity_sum += similarity\n",
    "\n",
    "            rating = product_sum / similarity_sum\n",
    "        else:\n",
    "            rating = 0.0\n",
    "            self.zero_prediction_count += 1\n",
    "\n",
    "        result = self.baseline_model.predict_baseline_rating(user_id, movie_id) + rating\n",
    "\n",
    "        return result\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.clear_predict_caches()\n",
    "        predictions = [self.predict_rating(row['userId'], row['movieId']) for _, row in x.iterrows()]\n",
    "        print 'used baseline predictions: %.1f%%' % (100.0 * self.zero_prediction_count / len(predictions))\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def build_model(ratings_df):\n",
    "    model = MovieSimilarityModel()\n",
    "    train_ratings_df, test_ratings_df = train_test_split(ratings_df)\n",
    "    model = model.fit(train_ratings_df)\n",
    "\n",
    "    x_train, y_train = get_xy(train_ratings_df)\n",
    "    x_test, y_test = get_xy(test_ratings_df)\n",
    "\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, y_train_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    print 'train score: %.4f, test score: %.4f' % (train_score, test_score)\n",
    "    print 'train rmse: %.4f, test rmse: %.4f' % (train_rmse, test_rmse)\n",
    "\n",
    "    \n",
    "ratings_df = read_ratings_df_with_timestamp('ml-latest-small/ratings.csv')\n",
    "\n",
    "with elapsed_time('build model'):\n",
    "    build_model(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
